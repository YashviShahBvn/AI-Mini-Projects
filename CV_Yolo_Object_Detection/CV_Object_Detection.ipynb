{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgz8mkVXnJeaV4ZTom3zjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashviShahBvn/AI-Mini-Projects/blob/main/CV_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "klilYqPTFzrQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main class\n",
        "\n",
        "class ObjectDetector:\n",
        "    def __init__(self):\n",
        "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\") # Pretrained weights\n",
        "        self.classes = []\n",
        "        with open(\"coco.names\", \"r\") as f: # names of the classes\n",
        "            self.classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        self.layer_names = self.net.getLayerNames()\n",
        "        self.output_layers = [self.layer_names[i - 1]\n",
        "                             for i in self.net.getUnconnectedOutLayers()]\n",
        "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
        "\n",
        "    def detect_objects(self, image_path):\n",
        "        img = cv2.imread(image_path)\n",
        "        height, width, channels = img.shape\n",
        "\n",
        "        blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "        self.net.setInput(blob)\n",
        "        outs = self.net.forward(self.output_layers)\n",
        "\n",
        "        class_ids = []\n",
        "        confidences = []\n",
        "        boxes = []\n",
        "\n",
        "        for out in outs:\n",
        "            for detection in out:\n",
        "                scores = detection[5:]\n",
        "                class_id = np.argmax(scores)\n",
        "                confidence = scores[class_id]\n",
        "                if confidence > 0.5:\n",
        "                    center_x = int(detection[0] * width)\n",
        "                    center_y = int(detection[1] * height)\n",
        "                    w = int(detection[2] * width)\n",
        "                    h = int(detection[3] * height)\n",
        "                    x = int(center_x - w / 2)\n",
        "                    y = int(center_y - h / 2)\n",
        "                    boxes.append([x, y, w, h])\n",
        "                    confidences.append(float(confidence))\n",
        "                    class_ids.append(class_id)\n",
        "\n",
        "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(self.classes[class_ids[i]])\n",
        "                color = self.colors[class_ids[i]]\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "                cv2.putText(img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        output_path = 'detected_' + Path(image_path).name\n",
        "        cv2.imwrite(output_path, img)\n",
        "        print(f\"Detection complete. Saved to {output_path}\")\n",
        "        return class_ids, confidences, boxes"
      ],
      "metadata": {
        "id": "lCayblGSFP_8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation\n",
        "\n",
        "### Constructor\n",
        "\n",
        "1. Load weights and structure (cgf)\n",
        "2. Load classes names from coco dataset (80 classes)\n",
        "3. Get Netwrok Layers => YOLOv3 has 3 output layers\n",
        "    1. 13x13 grid\n",
        "    2. 26x26 grid\n",
        "    3. 52x52 grid\n",
        "4. Generate colours for visualization\n",
        "\n",
        "### Detect object (main function)\n",
        "\n",
        "1. Load and preprocess image (create BLOB, resize, convert BGRâ†’RGB)\n",
        "2. Feed image to network and get output detections in \"outs\" var => This var will contain of the 3 types of output provided by YOLOv3\n",
        "3. Process all raw detections\n",
        "    1. Filter based on confidence\n",
        "    2. NMS => Remove overlapping boxes, etc\n",
        "4. Draw outlines on boxes\n",
        "5. Save final image"
      ],
      "metadata": {
        "id": "sjj1vTJwGJKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "if __name__ == \"__main__\":\n",
        "    detector = ObjectDetector()\n",
        "    detector.detect_objects('Yolo_Test_image.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlSbgY3CFR4J",
        "outputId": "79711958-5b4a-4df5-8468-453867e13c62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection complete. Saved to detected_Yolo_Test_image.jpg\n"
          ]
        }
      ]
    }
  ]
}